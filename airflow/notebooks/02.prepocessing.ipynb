{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Preprocessing del Testo per la Sentiment Analysis\n",
    "\n",
    "Il preprocessing del testo è un passaggio fondamentale per migliorare la performance dei modelli di machine learning, in quanto aiuta a ridurre la variabilità e a concentrare il modello sulle caratteristiche più rilevanti del testo.\n",
    "\n",
    "### Passaggi di Preprocessing\n",
    "\n",
    "1. **Caricamento del Dataset**\n",
    "   - Il dataset è stato caricato utilizzando la libreria `pandas`:\n",
    "     Il file CSV contiene due colonne: `label` (indicante il sentiment) e `text` (contenente i testi da analizzare).\n",
    "\n",
    "2. **Rimozione delle Stopwords**\n",
    "   - Le **stopwords** (parole comuni come \"the\", \"and\", \"is\") sono state rimosse dal testo. Queste parole non forniscono informazioni significative per la sentiment analysis.\n",
    "     - Utilizzo della libreria `nltk` per ottenere la lista di stopwords in inglese:\n",
    "       ```python\n",
    "       stop_words = set(stopwords.words('english'))\n",
    "       ```\n",
    "\n",
    "3. **Funzione di Preprocessing**\n",
    "   - È stata definita una funzione di preprocessing per elaborare ogni testo nel dataset:\n",
    "     La funzione esegue le seguenti operazioni:\n",
    "\n",
    "     - **Conversione in minuscolo**: Tutto il testo viene convertito in minuscolo per ridurre la variabilità causata dalla maiuscola/minuscola.\n",
    "     - **Rimozione dei numeri**: I numeri vengono rimossi, poiché non sono considerati rilevanti per la sentiment analysis.\n",
    "       ```python\n",
    "       text = re.sub(r'\\d+', '', text)\n",
    "       ```\n",
    "     - **Rimozione della punteggiatura**: I caratteri di punteggiatura (come punti, virgole, ecc.) vengono eliminati, poiché non aggiungono valore al sentiment.\n",
    "       ```python\n",
    "       text = re.sub(r'[^\\w\\s]', '', text)\n",
    "       ```\n",
    "     - **Tokenizzazione**: Il testo viene suddiviso in parole separate utilizzando la libreria `nltk`.\n",
    "       ```python\n",
    "       words = nltk.word_tokenize(text)\n",
    "       ```\n",
    "     - **Rimozione delle stopwords**: Le parole comuni (stopwords) vengono eliminate.\n",
    "     - **Stamming e Lemmatizzazione**: Ogni parola viene ridotta alla sua forma base (lemma) utilizzando il lemmatizzatore `WordNetLemmatizer` della libreria `nltk`. Questo aiuta a ridurre la variabilità delle parole (es. \"running\" diventa \"run\").\n",
    "     - **Eliminazione delle frasi con una lunghezza inferiore o uguale a 2 parole**: Frasi molto corte, come \"welcome\", \"cloud\", \"thik\", o singole parole, spesso non offrono un contesto sufficiente per un'analisi semantica accurata. Queste frasi non contribuiscono in modo significativo alla comprensione del sentiment e potrebbero introdurre rumore nel modello di machine learning.\n",
    "\n",
    "4. **Applicazione del Preprocessing al Dataset**\n",
    "   - La funzione di preprocessing è stata applicata a ogni riga del dataset nella colonna `text`, creando una nuova colonna `cleaned_text` che contiene il testo preprocessato."
   ],
   "id": "46b5fe7056eafa23"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
