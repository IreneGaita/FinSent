{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d867b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mario\\Desktop\\NLP\\FinSent\\env_nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "705c2f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>according gran company plan move production ru...</td>\n",
       "      <td>5</td>\n",
       "      <td>russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>technopolis plan develop stage area less NUM s...</td>\n",
       "      <td>4</td>\n",
       "      <td>sq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>international electronic industry company elco...</td>\n",
       "      <td>51</td>\n",
       "      <td>elcoteq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>new production plant company would increase ca...</td>\n",
       "      <td>7</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>according company updated strategy year NUM NU...</td>\n",
       "      <td>34</td>\n",
       "      <td>basware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "0   neutral  According to Gran , the company has no plans t...   \n",
       "1   neutral  Technopolis plans to develop in stages an area...   \n",
       "2  negative  The international electronic industry company ...   \n",
       "3  positive  With the new production plant the company woul...   \n",
       "4  positive  According to the company 's updated strategy f...   \n",
       "\n",
       "                                        cleaned_text  topic topic_name  \n",
       "0  according gran company plan move production ru...      5     russia  \n",
       "1  technopolis plan develop stage area less NUM s...      4         sq  \n",
       "2  international electronic industry company elco...     51    elcoteq  \n",
       "3  new production plant company would increase ca...      7      paper  \n",
       "4  according company updated strategy year NUM NU...     34    basware  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"../data/topic/topics_aggressive.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ac442ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec_embeddings(texts, model):\n",
    "\n",
    "    embeddings = []\n",
    "    for text in tqdm(texts, desc=\"Calcolo embedding Word2Vec\"):\n",
    "        words = text.split()\n",
    "        vectors = [model[w] for w in words if w in model]\n",
    "        if vectors:\n",
    "            embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(model.vector_size))\n",
    "    return np.array(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee6f9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sbert_embeddings(texts):\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    return model.encode(texts, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51806f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_cls_embeddings(texts, model_name=\"bert-base-uncased\"):\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "    import torch\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    all_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for text in tqdm(texts, desc=\"Embedding BERT CLS\", unit=\"text\"):\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "            outputs = model(**inputs)\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "            all_embeddings.append(cls_embedding)\n",
    "    return np.array(all_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38740a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calcolo embedding Word2Vec: 100%|██████████| 4821/4821 [00:00<00:00, 7556.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4821 word2vec embeddings saved.\n",
      "length of each embedding: 300\n"
     ]
    }
   ],
   "source": [
    "# dowload the GoogleNews-vectors-negative300.bin.gz file and add it in the embeddings folder.\n",
    "# link https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?resourcekey=0-wjGZdNAUop6WykTtMip30g\n",
    "\n",
    "model_path = \"../data/embeddings/GoogleNews-vectors-negative300.bin\"\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "\n",
    "embeddings_word2vec = get_word2vec_embeddings(df[\"cleaned_text\"], word2vec_model)\n",
    "np.save(\"../data/embeddings/embeddings_word2vec.npy\", embeddings_word2vec)\n",
    "\n",
    "print(f\"{len(embeddings_word2vec)} word2vec embeddings saved.\")\n",
    "print(f\"length of each embedding: {len(embeddings_word2vec[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "519fc61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 151/151 [00:28<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4821 sbert embeddings saved.\n",
      "length of each embedding: 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings_sbert = get_sbert_embeddings(df[\"cleaned_text\"])\n",
    "np.save(\"../data/embeddings/embeddings_sbert.npy\", embeddings_sbert)\n",
    "\n",
    "print(f\"{len(embeddings_sbert)} sbert embeddings saved.\")\n",
    "print(f\"length of each embedding: {len(embeddings_sbert[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69ad6d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding BERT CLS: 100%|██████████| 4821/4821 [04:39<00:00, 17.24text/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4821 bert embeddings saved.\n",
      "length of each embedding: 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings_bert = get_bert_cls_embeddings(df[\"cleaned_text\"])\n",
    "np.save(\"../data/embeddings/embeddings_bert.npy\", embeddings_bert)\n",
    "\n",
    "print(f\"{len(embeddings_bert)} bert embeddings saved.\")\n",
    "print(f\"length of each embedding: {len(embeddings_bert[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da95e133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding BERT CLS: 100%|██████████| 4821/4821 [04:13<00:00, 19.00text/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4821 finbert embeddings saved.\n",
      "length of each embedding: 768\n"
     ]
    }
   ],
   "source": [
    "embeddings_finbert = get_bert_cls_embeddings(df[\"cleaned_text\"], model_name=\"yiyanghkust/finbert-tone\")\n",
    "\n",
    "np.save(\"../data/embeddings/embeddings_finbert.npy\", embeddings_finbert)\n",
    "print(f\"{len(embeddings_finbert)} finbert embeddings saved.\")\n",
    "print(f\"length of each embedding: {len(embeddings_finbert[0])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
